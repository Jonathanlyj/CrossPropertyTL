
2024-03-20 20:20:53.510906:job config: {'train_data_path': '/data/yll6162/alignntl_dft_3d/tl_dataset/dataset_alignn_bert-base-uncased_chemnlp_prop_Tc_supercon_train.csv', 'val_data_path': '/data/yll6162/alignntl_dft_3d/tl_dataset/dataset_alignn_bert-base-uncased_chemnlp_prop_Tc_supercon_val.csv', 'test_data_path': '/data/yll6162/alignntl_dft_3d/tl_dataset/dataset_alignn_bert-base-uncased_chemnlp_prop_Tc_supercon_test.csv', 'label': 'Tc_supercon', 'input_type': None, 'log_folder': 'log', 'log_file': 'alignn_bert-base-uncased_chemnlp_prop_Tc_supercon.log', 'test_metric': 'mae', 'architecture': '1024Rx4D-512Rx3D-256Rx3D-128Rx3D-64Rx2-32Rx1-1', 'model_seed': 0, 'loss_type': 'mae', 'config_file': 'sample/alignn_bert-base-uncased_chemnlp_prop_Tc_supercon_job.config', 'use_valid': True, 'project': 'MOF', 'regressors': None, 'input_types': None, 'paramsGrid': {'optimizer': 'Adam', 'learning_rate': 0.0001, 'patience': 100, 'dropouts': [0.8, 0.9, 0.7, 0.8], 'EVAL_FREQUENCY': 1000}, 'save_path': 'sample/alignn_bert-base-uncased_chemnlp_prop_Tc_supercon', 'model_path': None, 'last_layer_with_weight': True, 'keras_path': 'model/alignn_bert-base-uncased_chemnlp_prop_Tc_supercon', 'test_size': None, 'val_size': None}
2024-03-20 20:20:53.510977:train data path is  /data/yll6162/alignntl_dft_3d/tl_dataset/dataset_alignn_bert-base-uncased_chemnlp_prop_Tc_supercon_train.csv
2024-03-20 20:20:54.107116:input attribute sets are:  None
2024-03-20 20:20:54.107281:test data path is  /data/yll6162/alignntl_dft_3d/tl_dataset/dataset_alignn_bert-base-uncased_chemnlp_prop_Tc_supercon_test.csv
2024-03-20 20:20:54.334286:val data path is  /data/yll6162/alignntl_dft_3d/tl_dataset/dataset_alignn_bert-base-uncased_chemnlp_prop_Tc_supercon_val.csv
2024-03-20 20:20:54.636289:input attributes are:  Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
       ...
       '758.1', '759.1', '760.1', '761.1', '762.1', '763.1', '764.1', '765.1',
       '766.1', '767.1'],
      dtype='object', length=1536)
2024-03-20 20:20:54.636599:label: Tc_supercon
2024-03-20 20:21:08.108230: train, test, valid sizes:  (842, 1536) (842,) (106, 1536) (106,) (106, 1536) (106,)
2024-03-20 20:21:08.115171:train matrix shape of train_X:  (842, 1536)  train_y:  (842,)
2024-03-20 20:21:08.115322:valid matrix shape of train_X:  (106, 1536)  valid_y:  (106,)
2024-03-20 20:21:08.115371:test matrix shape of valid_X:   (106, 1536)  test_y:  (106,)
2024-03-20 20:21:08.115414:architecture is:  1024Rx4D-512Rx3D-256Rx3D-128Rx3D-64Rx2-32Rx1-1
2024-03-20 20:21:08.115467:learning rate is  0.0001
2024-03-20 20:21:08.115508:model path is  None
2024-03-20 20:21:08.125422:adding fully connected layers with 1024 outputs
2024-03-20 20:21:08.898940:adding residual with fc as the size are different
2024-03-20 20:21:08.930944:adding fully connected layers with 1024 outputs
2024-03-20 20:21:08.954411:adding residual, both sizes are same
2024-03-20 20:21:08.964412:adding fully connected layers with 1024 outputs
2024-03-20 20:21:08.988847:adding residual, both sizes are same
2024-03-20 20:21:08.998710:adding fully connected layers with 1024 outputs
2024-03-20 20:21:09.022897:adding residual, both sizes are same
2024-03-20 20:21:09.035269:adding dropout 0.8
2024-03-20 20:21:09.063318:adding fully connected layers with 512 outputs
2024-03-20 20:21:09.090850:adding residual with fc as the size are different
2024-03-20 20:21:09.112286:adding fully connected layers with 512 outputs
2024-03-20 20:21:09.124100:adding residual, both sizes are same
2024-03-20 20:21:09.131056:adding fully connected layers with 512 outputs
2024-03-20 20:21:09.141624:adding residual, both sizes are same
2024-03-20 20:21:09.145674:adding dropout 0.9
2024-03-20 20:21:09.149187:adding fully connected layers with 256 outputs
2024-03-20 20:21:09.160882:adding residual with fc as the size are different
2024-03-20 20:21:09.174091:adding fully connected layers with 256 outputs
2024-03-20 20:21:09.184530:adding residual, both sizes are same
2024-03-20 20:21:09.189399:adding fully connected layers with 256 outputs
2024-03-20 20:21:09.199213:adding residual, both sizes are same
2024-03-20 20:21:09.203110:adding dropout 0.7
2024-03-20 20:21:09.206508:adding fully connected layers with 128 outputs
2024-03-20 20:21:09.217058:adding residual with fc as the size are different
2024-03-20 20:21:09.230691:adding fully connected layers with 128 outputs
2024-03-20 20:21:09.241196:adding residual, both sizes are same
2024-03-20 20:21:09.245241:adding fully connected layers with 128 outputs
2024-03-20 20:21:09.255655:adding residual, both sizes are same
2024-03-20 20:21:09.259625:adding dropout 0.8
2024-03-20 20:21:09.263193:adding fully connected layers with 64 outputs
2024-03-20 20:21:09.273897:adding residual with fc as the size are different
2024-03-20 20:21:09.287580:adding fully connected layers with 64 outputs
2024-03-20 20:21:09.295474:adding residual, both sizes are same
2024-03-20 20:21:09.297444:adding fully connected layers with 32 outputs
2024-03-20 20:21:09.303394:adding residual with fc as the size are different
2024-03-20 20:21:09.311223:adding final layer with 1 output
2024-03-20 20:21:09.323071:Model: "ElemNet"
2024-03-20 20:21:09.323194:__________________________________________________________________________________________________
2024-03-20 20:21:09.323245:Layer (type)                    Output Shape         Param #     Connected to                     
2024-03-20 20:21:09.323283:==================================================================================================
2024-03-20 20:21:09.323514:elemental_fractions (InputLayer [(None, 1536)]       0                                            
2024-03-20 20:21:09.323568:__________________________________________________________________________________________________
2024-03-20 20:21:09.323746:fc0_0 (Dense)                   (None, 1024)         1573888     elemental_fractions[0][0]        
2024-03-20 20:21:09.323794:__________________________________________________________________________________________________
2024-03-20 20:21:09.323911:fc0_dim_0 (Dense)               (None, 1024)         1573888     elemental_fractions[0][0]        
2024-03-20 20:21:09.323956:__________________________________________________________________________________________________
2024-03-20 20:21:09.324042:tf.__operators__.add (TFOpLambd (None, 1024)         0           fc0_0[0][0]                      
2024-03-20 20:21:09.324088:                                                                 fc0_dim_0[0][0]                  
2024-03-20 20:21:09.324126:__________________________________________________________________________________________________
2024-03-20 20:21:09.324236:fc0_1 (Dense)                   (None, 1024)         1049600     tf.__operators__.add[0][0]       
2024-03-20 20:21:09.324280:__________________________________________________________________________________________________
2024-03-20 20:21:09.324359:tf.__operators__.add_1 (TFOpLam (None, 1024)         0           fc0_1[0][0]                      
2024-03-20 20:21:09.324404:                                                                 tf.__operators__.add[0][0]       
2024-03-20 20:21:09.324440:__________________________________________________________________________________________________
2024-03-20 20:21:09.324563:fc0_2 (Dense)                   (None, 1024)         1049600     tf.__operators__.add_1[0][0]     
2024-03-20 20:21:09.324607:__________________________________________________________________________________________________
2024-03-20 20:21:09.324686:tf.__operators__.add_2 (TFOpLam (None, 1024)         0           fc0_2[0][0]                      
2024-03-20 20:21:09.324731:                                                                 tf.__operators__.add_1[0][0]     
2024-03-20 20:21:09.324767:__________________________________________________________________________________________________
2024-03-20 20:21:09.324874:fc0_3 (Dense)                   (None, 1024)         1049600     tf.__operators__.add_2[0][0]     
2024-03-20 20:21:09.324917:__________________________________________________________________________________________________
2024-03-20 20:21:09.324995:tf.__operators__.add_3 (TFOpLam (None, 1024)         0           fc0_3[0][0]                      
2024-03-20 20:21:09.325050:                                                                 tf.__operators__.add_2[0][0]     
2024-03-20 20:21:09.325087:__________________________________________________________________________________________________
2024-03-20 20:21:09.325166:dropout (Dropout)               (None, 1024)         0           tf.__operators__.add_3[0][0]     
2024-03-20 20:21:09.325204:__________________________________________________________________________________________________
2024-03-20 20:21:09.325312:fc1_0 (Dense)                   (None, 512)          524800      dropout[0][0]                    
2024-03-20 20:21:09.325356:__________________________________________________________________________________________________
2024-03-20 20:21:09.325468:fc1_dim_0 (Dense)               (None, 512)          524800      dropout[0][0]                    
2024-03-20 20:21:09.325514:__________________________________________________________________________________________________
2024-03-20 20:21:09.325594:tf.__operators__.add_4 (TFOpLam (None, 512)          0           fc1_0[0][0]                      
2024-03-20 20:21:09.325638:                                                                 fc1_dim_0[0][0]                  
2024-03-20 20:21:09.325674:__________________________________________________________________________________________________
2024-03-20 20:21:09.325784:fc1_1 (Dense)                   (None, 512)          262656      tf.__operators__.add_4[0][0]     
2024-03-20 20:21:09.325832:__________________________________________________________________________________________________
2024-03-20 20:21:09.325911:tf.__operators__.add_5 (TFOpLam (None, 512)          0           fc1_1[0][0]                      
2024-03-20 20:21:09.325955:                                                                 tf.__operators__.add_4[0][0]     
2024-03-20 20:21:09.325992:__________________________________________________________________________________________________
2024-03-20 20:21:09.326096:fc1_2 (Dense)                   (None, 512)          262656      tf.__operators__.add_5[0][0]     
2024-03-20 20:21:09.326141:__________________________________________________________________________________________________
2024-03-20 20:21:09.326219:tf.__operators__.add_6 (TFOpLam (None, 512)          0           fc1_2[0][0]                      
2024-03-20 20:21:09.326263:                                                                 tf.__operators__.add_5[0][0]     
2024-03-20 20:21:09.326301:__________________________________________________________________________________________________
2024-03-20 20:21:09.326376:dropout_1 (Dropout)             (None, 512)          0           tf.__operators__.add_6[0][0]     
2024-03-20 20:21:09.326414:__________________________________________________________________________________________________
2024-03-20 20:21:09.326525:fc2_0 (Dense)                   (None, 256)          131328      dropout_1[0][0]                  
2024-03-20 20:21:09.326570:__________________________________________________________________________________________________
2024-03-20 20:21:09.326674:fc2_dim_0 (Dense)               (None, 256)          131328      dropout_1[0][0]                  
2024-03-20 20:21:09.326723:__________________________________________________________________________________________________
2024-03-20 20:21:09.326801:tf.__operators__.add_7 (TFOpLam (None, 256)          0           fc2_0[0][0]                      
2024-03-20 20:21:09.326845:                                                                 fc2_dim_0[0][0]                  
2024-03-20 20:21:09.326883:__________________________________________________________________________________________________
2024-03-20 20:21:09.326988:fc2_1 (Dense)                   (None, 256)          65792       tf.__operators__.add_7[0][0]     
2024-03-20 20:21:09.327032:__________________________________________________________________________________________________
2024-03-20 20:21:09.327118:tf.__operators__.add_8 (TFOpLam (None, 256)          0           fc2_1[0][0]                      
2024-03-20 20:21:09.327162:                                                                 tf.__operators__.add_7[0][0]     
2024-03-20 20:21:09.327199:__________________________________________________________________________________________________
2024-03-20 20:21:09.327303:fc2_2 (Dense)                   (None, 256)          65792       tf.__operators__.add_8[0][0]     
2024-03-20 20:21:09.327367:__________________________________________________________________________________________________
2024-03-20 20:21:09.327454:tf.__operators__.add_9 (TFOpLam (None, 256)          0           fc2_2[0][0]                      
2024-03-20 20:21:09.327506:                                                                 tf.__operators__.add_8[0][0]     
2024-03-20 20:21:09.327544:__________________________________________________________________________________________________
2024-03-20 20:21:09.327619:dropout_2 (Dropout)             (None, 256)          0           tf.__operators__.add_9[0][0]     
2024-03-20 20:21:09.327658:__________________________________________________________________________________________________
2024-03-20 20:21:09.327764:fc3_0 (Dense)                   (None, 128)          32896       dropout_2[0][0]                  
2024-03-20 20:21:09.327807:__________________________________________________________________________________________________
2024-03-20 20:21:09.327909:fc3_dim_0 (Dense)               (None, 128)          32896       dropout_2[0][0]                  
2024-03-20 20:21:09.327952:__________________________________________________________________________________________________
2024-03-20 20:21:09.328030:tf.__operators__.add_10 (TFOpLa (None, 128)          0           fc3_0[0][0]                      
2024-03-20 20:21:09.328073:                                                                 fc3_dim_0[0][0]                  
2024-03-20 20:21:09.328109:__________________________________________________________________________________________________
2024-03-20 20:21:09.328212:fc3_1 (Dense)                   (None, 128)          16512       tf.__operators__.add_10[0][0]    
2024-03-20 20:21:09.328254:__________________________________________________________________________________________________
2024-03-20 20:21:09.328330:tf.__operators__.add_11 (TFOpLa (None, 128)          0           fc3_1[0][0]                      
2024-03-20 20:21:09.328373:                                                                 tf.__operators__.add_10[0][0]    
2024-03-20 20:21:09.328410:__________________________________________________________________________________________________
2024-03-20 20:21:09.328531:fc3_2 (Dense)                   (None, 128)          16512       tf.__operators__.add_11[0][0]    
2024-03-20 20:21:09.328574:__________________________________________________________________________________________________
2024-03-20 20:21:09.328652:tf.__operators__.add_12 (TFOpLa (None, 128)          0           fc3_2[0][0]                      
2024-03-20 20:21:09.328695:                                                                 tf.__operators__.add_11[0][0]    
2024-03-20 20:21:09.328732:__________________________________________________________________________________________________
2024-03-20 20:21:09.328807:dropout_3 (Dropout)             (None, 128)          0           tf.__operators__.add_12[0][0]    
2024-03-20 20:21:09.328846:__________________________________________________________________________________________________
2024-03-20 20:21:09.328949:fc4_0 (Dense)                   (None, 64)           8256        dropout_3[0][0]                  
2024-03-20 20:21:09.328992:__________________________________________________________________________________________________
2024-03-20 20:21:09.329095:fc4_dim_0 (Dense)               (None, 64)           8256        dropout_3[0][0]                  
2024-03-20 20:21:09.329138:__________________________________________________________________________________________________
2024-03-20 20:21:09.329221:tf.__operators__.add_13 (TFOpLa (None, 64)           0           fc4_0[0][0]                      
2024-03-20 20:21:09.329265:                                                                 fc4_dim_0[0][0]                  
2024-03-20 20:21:09.329300:__________________________________________________________________________________________________
2024-03-20 20:21:09.329404:fc4_1 (Dense)                   (None, 64)           4160        tf.__operators__.add_13[0][0]    
2024-03-20 20:21:09.329447:__________________________________________________________________________________________________
2024-03-20 20:21:09.329535:tf.__operators__.add_14 (TFOpLa (None, 64)           0           fc4_1[0][0]                      
2024-03-20 20:21:09.329578:                                                                 tf.__operators__.add_13[0][0]    
2024-03-20 20:21:09.329614:__________________________________________________________________________________________________
2024-03-20 20:21:09.329722:fc5_0 (Dense)                   (None, 32)           2080        tf.__operators__.add_14[0][0]    
2024-03-20 20:21:09.329771:__________________________________________________________________________________________________
2024-03-20 20:21:09.329877:fc5_dim_0 (Dense)               (None, 32)           2080        tf.__operators__.add_14[0][0]    
2024-03-20 20:21:09.333244:__________________________________________________________________________________________________
2024-03-20 20:21:09.333487:tf.__operators__.add_15 (TFOpLa (None, 32)           0           fc5_0[0][0]                      
2024-03-20 20:21:09.333563:                                                                 fc5_dim_0[0][0]                  
2024-03-20 20:21:09.333617:__________________________________________________________________________________________________
2024-03-20 20:21:09.333800:fc6 (Dense)                     (None, 1)            33          tf.__operators__.add_15[0][0]    
2024-03-20 20:21:09.333865:==================================================================================================
2024-03-20 20:21:09.335011:Total params: 8,389,409
2024-03-20 20:21:09.335090:Trainable params: 8,389,409
2024-03-20 20:21:09.335146:Non-trainable params: 0
2024-03-20 20:21:09.335196:__________________________________________________________________________________________________
2024-03-20 20:21:09.349981:start training
2024-03-20 20:21:11.944730:2024-03-20 20:21:11.944665: Current epoch: 0, loss: 18.41356658935547, validation loss: 6.3577775955200195
2024-03-20 20:21:12.272381:2024-03-20 20:21:12.272308: Current epoch: 1, loss: 6.839293956756592, validation loss: 13.272759437561035
2024-03-20 20:21:12.705638:2024-03-20 20:21:12.705339: Current epoch: 2, loss: 7.29005765914917, validation loss: 4.667544841766357
2024-03-20 20:21:13.036094:2024-03-20 20:21:13.035801: Current epoch: 3, loss: 4.786031246185303, validation loss: 4.129358768463135
2024-03-20 20:21:13.243663:2024-03-20 20:21:13.243593: Current epoch: 4, loss: 3.6743593215942383, validation loss: 7.484379768371582
2024-03-20 20:21:13.575802:2024-03-20 20:21:13.575738: Current epoch: 5, loss: 4.1331892013549805, validation loss: 3.262847423553467
2024-03-20 20:21:13.955489:2024-03-20 20:21:13.955422: Current epoch: 6, loss: 3.5734033584594727, validation loss: 4.319972515106201
2024-03-20 20:21:14.321237:2024-03-20 20:21:14.321190: Current epoch: 7, loss: 3.3251116275787354, validation loss: 3.4479949474334717
2024-03-20 20:21:14.789376:2024-03-20 20:21:14.789306: Current epoch: 8, loss: 4.225282192230225, validation loss: 3.7831597328186035
2024-03-20 20:21:15.108931:2024-03-20 20:21:15.108867: Current epoch: 9, loss: 3.2001304626464844, validation loss: 5.750916004180908
2024-03-20 20:21:19.797425:2024-03-20 20:21:19.797335: Current epoch: 10, loss: 3.7719874382019043, validation loss: 3.2530672550201416
2024-03-20 20:21:20.175019:2024-03-20 20:21:20.174921: Current epoch: 11, loss: 3.6555533409118652, validation loss: 2.659122943878174
2024-03-20 20:21:20.525463:2024-03-20 20:21:20.525391: Current epoch: 12, loss: 2.9795455932617188, validation loss: 2.6314547061920166
2024-03-20 20:21:20.938067:2024-03-20 20:21:20.938005: Current epoch: 13, loss: 2.573909044265747, validation loss: 2.623115301132202
2024-03-20 20:21:21.319931:2024-03-20 20:21:21.319865: Current epoch: 14, loss: 2.3957550525665283, validation loss: 2.431056499481201
2024-03-20 20:21:21.768472:2024-03-20 20:21:21.768402: Current epoch: 15, loss: 2.4375805854797363, validation loss: 2.5271754264831543
2024-03-20 20:21:22.049676:2024-03-20 20:21:22.049637: Current epoch: 16, loss: 2.3868370056152344, validation loss: 2.9873476028442383
2024-03-20 20:21:22.364234:2024-03-20 20:21:22.364161: Current epoch: 17, loss: 2.295527458190918, validation loss: 2.3894870281219482
2024-03-20 20:21:22.748993:2024-03-20 20:21:22.748938: Current epoch: 18, loss: 2.3330297470092773, validation loss: 2.7931060791015625
2024-03-20 20:21:23.147378:2024-03-20 20:21:23.147307: Current epoch: 19, loss: 2.116187334060669, validation loss: 2.3227057456970215
2024-03-20 20:21:27.640108:2024-03-20 20:21:27.640024: Current epoch: 20, loss: 2.1302568912506104, validation loss: 2.213756561279297
2024-03-20 20:21:28.026623:2024-03-20 20:21:28.026564: Current epoch: 21, loss: 1.6847742795944214, validation loss: 2.1078908443450928
2024-03-20 20:21:28.340508:2024-03-20 20:21:28.340325: Current epoch: 22, loss: 1.6603379249572754, validation loss: 2.263740062713623
2024-03-20 20:21:28.636352:2024-03-20 20:21:28.636288: Current epoch: 23, loss: 1.6575230360031128, validation loss: 2.1427664756774902
2024-03-20 20:21:28.849253:2024-03-20 20:21:28.849208: Current epoch: 24, loss: 1.5173286199569702, validation loss: 2.4304897785186768
2024-03-20 20:21:29.187772:2024-03-20 20:21:29.187734: Current epoch: 25, loss: 1.7379142045974731, validation loss: 2.322181463241577
2024-03-20 20:21:29.576984:2024-03-20 20:21:29.576951: Current epoch: 26, loss: 1.7144213914871216, validation loss: 2.42919921875
2024-03-20 20:21:29.963211:2024-03-20 20:21:29.963131: Current epoch: 27, loss: 1.7364333868026733, validation loss: 1.9910311698913574
2024-03-20 20:21:30.161759:2024-03-20 20:21:30.161718: Current epoch: 28, loss: 1.5639234781265259, validation loss: 2.116431474685669
2024-03-20 20:21:30.517352:2024-03-20 20:21:30.517291: Current epoch: 29, loss: 1.367051601409912, validation loss: 2.6759896278381348
2024-03-20 20:21:30.808380:2024-03-20 20:21:30.808331: Current epoch: 30, loss: 1.6831262111663818, validation loss: 2.221487045288086
2024-03-20 20:21:31.138992:2024-03-20 20:21:31.138944: Current epoch: 31, loss: 1.3705812692642212, validation loss: 2.2895236015319824
2024-03-20 20:21:31.487793:2024-03-20 20:21:31.487750: Current epoch: 32, loss: 1.6269810199737549, validation loss: 2.2537992000579834
2024-03-20 20:21:31.886416:2024-03-20 20:21:31.886375: Current epoch: 33, loss: 1.318116545677185, validation loss: 2.1239571571350098
2024-03-20 20:21:32.483154:2024-03-20 20:21:32.483098: Current epoch: 34, loss: 1.775934100151062, validation loss: 2.1054346561431885
2024-03-20 20:21:32.854215:2024-03-20 20:21:32.854126: Current epoch: 35, loss: 1.4675449132919312, validation loss: 1.893452763557434
2024-03-20 20:21:33.214719:2024-03-20 20:21:33.214675: Current epoch: 36, loss: 1.1673794984817505, validation loss: 2.0418100357055664
2024-03-20 20:21:33.584643:2024-03-20 20:21:33.584595: Current epoch: 37, loss: 1.154702067375183, validation loss: 2.2370121479034424
2024-03-20 20:21:34.052774:2024-03-20 20:21:34.052685: Current epoch: 38, loss: 1.1499547958374023, validation loss: 2.3389618396759033
2024-03-20 20:21:34.307962:2024-03-20 20:21:34.307927: Current epoch: 39, loss: 1.386994481086731, validation loss: 2.246509075164795
2024-03-20 20:21:39.191572:2024-03-20 20:21:39.191440: Current epoch: 40, loss: 1.4111334085464478, validation loss: 1.8123160600662231
2024-03-20 20:21:39.598365:2024-03-20 20:21:39.598318: Current epoch: 41, loss: 1.2441767454147339, validation loss: 1.8532408475875854
2024-03-20 20:21:39.841771:2024-03-20 20:21:39.841726: Current epoch: 42, loss: 1.478965163230896, validation loss: 2.2952663898468018
2024-03-20 20:21:40.128043:2024-03-20 20:21:40.127995: Current epoch: 43, loss: 1.1215806007385254, validation loss: 1.8276104927062988
2024-03-20 20:21:40.525633:2024-03-20 20:21:40.525568: Current epoch: 44, loss: 1.2086772918701172, validation loss: 1.8778525590896606
2024-03-20 20:21:40.945062:2024-03-20 20:21:40.945024: Current epoch: 45, loss: 1.2145096063613892, validation loss: 1.844224452972412
2024-03-20 20:21:41.335633:2024-03-20 20:21:41.335589: Current epoch: 46, loss: 1.215434193611145, validation loss: 2.2615346908569336
2024-03-20 20:21:41.570221:2024-03-20 20:21:41.570158: Current epoch: 47, loss: 1.3615065813064575, validation loss: 2.058414936065674
2024-03-20 20:21:41.809490:2024-03-20 20:21:41.809421: Current epoch: 48, loss: 1.2603209018707275, validation loss: 2.1404056549072266
2024-03-20 20:21:42.185153:2024-03-20 20:21:42.185085: Current epoch: 49, loss: 1.1129305362701416, validation loss: 1.9841641187667847
2024-03-20 20:21:47.165487:2024-03-20 20:21:47.165318: Current epoch: 50, loss: 1.4085252285003662, validation loss: 2.063880681991577
2024-03-20 20:21:47.566174:2024-03-20 20:21:47.566092: Current epoch: 51, loss: 1.3156604766845703, validation loss: 1.9961978197097778
2024-03-20 20:21:47.936346:2024-03-20 20:21:47.936288: Current epoch: 52, loss: 1.2600032091140747, validation loss: 2.0145254135131836
2024-03-20 20:21:48.469707:2024-03-20 20:21:48.469612: Current epoch: 53, loss: 1.2079252004623413, validation loss: 1.8918542861938477
2024-03-20 20:21:48.815396:2024-03-20 20:21:48.815355: Current epoch: 54, loss: 1.0101475715637207, validation loss: 1.878509521484375
2024-03-20 20:21:49.121496:2024-03-20 20:21:49.121430: Current epoch: 55, loss: 1.4234975576400757, validation loss: 1.9100404977798462
2024-03-20 20:21:49.508496:2024-03-20 20:21:49.508420: Current epoch: 56, loss: 1.2320259809494019, validation loss: 2.2540910243988037
2024-03-20 20:21:49.879571:2024-03-20 20:21:49.879498: Current epoch: 57, loss: 1.1161937713623047, validation loss: 1.8894630670547485
2024-03-20 20:21:50.178006:2024-03-20 20:21:50.177953: Current epoch: 58, loss: 1.1915733814239502, validation loss: 2.173603057861328
2024-03-20 20:21:50.573186:2024-03-20 20:21:50.573142: Current epoch: 59, loss: 1.0458565950393677, validation loss: 2.0591256618499756
2024-03-20 20:21:50.852928:2024-03-20 20:21:50.852887: Current epoch: 60, loss: 0.9541909694671631, validation loss: 1.98732590675354
2024-03-20 20:21:51.210977:2024-03-20 20:21:51.210908: Current epoch: 61, loss: 0.9835341572761536, validation loss: 1.778398036956787
2024-03-20 20:21:51.586842:2024-03-20 20:21:51.586776: Current epoch: 62, loss: 0.9784087538719177, validation loss: 2.000474691390991
2024-03-20 20:21:51.930531:2024-03-20 20:21:51.930464: Current epoch: 63, loss: 1.2262579202651978, validation loss: 1.7749607563018799
2024-03-20 20:21:52.342356:2024-03-20 20:21:52.342287: Current epoch: 64, loss: 0.9837267994880676, validation loss: 1.7989788055419922
2024-03-20 20:21:52.648428:2024-03-20 20:21:52.648381: Current epoch: 65, loss: 0.8810263276100159, validation loss: 1.821424961090088
2024-03-20 20:21:53.025904:2024-03-20 20:21:53.025848: Current epoch: 66, loss: 0.9196469783782959, validation loss: 1.7926478385925293
2024-03-20 20:21:53.419028:2024-03-20 20:21:53.418973: Current epoch: 67, loss: 0.894842803478241, validation loss: 2.03153395652771
2024-03-20 20:21:53.850085:2024-03-20 20:21:53.850027: Current epoch: 68, loss: 0.8643655776977539, validation loss: 1.80237877368927
2024-03-20 20:21:54.154065:2024-03-20 20:21:54.154032: Current epoch: 69, loss: 0.9414782524108887, validation loss: 1.9512815475463867
2024-03-20 20:21:58.557597:2024-03-20 20:21:58.557527: Current epoch: 70, loss: 0.9124062061309814, validation loss: 1.6215639114379883
2024-03-20 20:21:58.795764:2024-03-20 20:21:58.795724: Current epoch: 71, loss: 1.0209931135177612, validation loss: 2.1072964668273926
2024-03-20 20:21:59.123151:2024-03-20 20:21:59.123097: Current epoch: 72, loss: 0.9324024319648743, validation loss: 1.7473233938217163
2024-03-20 20:21:59.515973:2024-03-20 20:21:59.515902: Current epoch: 73, loss: 1.0858608484268188, validation loss: 2.0384676456451416
2024-03-20 20:22:00.044289:2024-03-20 20:22:00.044213: Current epoch: 74, loss: 0.8997074961662292, validation loss: 1.7569900751113892
2024-03-20 20:22:00.330741:2024-03-20 20:22:00.330681: Current epoch: 75, loss: 0.9068743586540222, validation loss: 1.802573561668396
2024-03-20 20:22:00.749820:2024-03-20 20:22:00.749779: Current epoch: 76, loss: 0.9568542838096619, validation loss: 2.0034213066101074
2024-03-20 20:22:01.137866:2024-03-20 20:22:01.137761: Current epoch: 77, loss: 0.9416084885597229, validation loss: 1.7684227228164673
2024-03-20 20:22:01.513300:2024-03-20 20:22:01.513261: Current epoch: 78, loss: 0.8226281404495239, validation loss: 1.822542428970337
2024-03-20 20:22:01.820540:2024-03-20 20:22:01.820473: Current epoch: 79, loss: 0.9180665612220764, validation loss: 1.7577717304229736
2024-03-20 20:22:06.694080:2024-03-20 20:22:06.693984: Current epoch: 80, loss: 0.8899516463279724, validation loss: 1.825042963027954
2024-03-20 20:22:07.103917:2024-03-20 20:22:07.103874: Current epoch: 81, loss: 0.9009536504745483, validation loss: 1.689435601234436
2024-03-20 20:22:07.447874:2024-03-20 20:22:07.447667: Current epoch: 82, loss: 0.829116940498352, validation loss: 1.7250463962554932
2024-03-20 20:22:07.694390:2024-03-20 20:22:07.694328: Current epoch: 83, loss: 0.8577848672866821, validation loss: 1.9315840005874634
2024-03-20 20:22:08.034497:2024-03-20 20:22:08.034429: Current epoch: 84, loss: 0.8343479633331299, validation loss: 1.8603063821792603
2024-03-20 20:22:08.414477:2024-03-20 20:22:08.414396: Current epoch: 85, loss: 1.0606707334518433, validation loss: 1.9154032468795776
2024-03-20 20:22:08.732697:2024-03-20 20:22:08.732621: Current epoch: 86, loss: 0.9689338207244873, validation loss: 1.7872059345245361
2024-03-20 20:22:09.023002:2024-03-20 20:22:09.022930: Current epoch: 87, loss: 0.8890264630317688, validation loss: 1.7645982503890991
2024-03-20 20:22:09.361189:2024-03-20 20:22:09.361130: Current epoch: 88, loss: 0.8644400238990784, validation loss: 1.9145402908325195
2024-03-20 20:22:09.639731:2024-03-20 20:22:09.639683: Current epoch: 89, loss: 0.7994598746299744, validation loss: 1.7872389554977417
2024-03-20 20:22:10.028622:2024-03-20 20:22:10.028578: Current epoch: 90, loss: 1.0140795707702637, validation loss: 1.770492672920227
2024-03-20 20:22:10.446252:2024-03-20 20:22:10.446126: Current epoch: 91, loss: 0.861494243144989, validation loss: 1.6906099319458008
2024-03-20 20:22:10.922425:2024-03-20 20:22:10.922378: Current epoch: 92, loss: 0.7263342142105103, validation loss: 1.7330403327941895
2024-03-20 20:22:11.326935:2024-03-20 20:22:11.326861: Current epoch: 93, loss: 0.8781476616859436, validation loss: 1.79641592502594
2024-03-20 20:22:11.619667:2024-03-20 20:22:11.619627: Current epoch: 94, loss: 0.9411665797233582, validation loss: 1.7065706253051758
2024-03-20 20:22:11.933583:2024-03-20 20:22:11.933521: Current epoch: 95, loss: 0.8385375142097473, validation loss: 1.7744226455688477
2024-03-20 20:22:12.336675:2024-03-20 20:22:12.336605: Current epoch: 96, loss: 0.7454643845558167, validation loss: 1.6741653680801392
2024-03-20 20:22:12.733963:2024-03-20 20:22:12.733908: Current epoch: 97, loss: 0.7664099931716919, validation loss: 1.7420357465744019
2024-03-20 20:22:13.138888:2024-03-20 20:22:13.138847: Current epoch: 98, loss: 0.7873190641403198, validation loss: 1.7440946102142334
2024-03-20 20:22:13.644153:2024-03-20 20:22:13.644089: Current epoch: 99, loss: 0.7613903880119324, validation loss: 1.798095941543579
2024-03-20 20:22:13.999240:2024-03-20 20:22:13.999211: Current epoch: 100, loss: 0.816582441329956, validation loss: 1.9114184379577637
2024-03-20 20:22:14.367418:2024-03-20 20:22:14.367377: Current epoch: 101, loss: 0.8129452466964722, validation loss: 1.6947370767593384
2024-03-20 20:22:14.753371:2024-03-20 20:22:14.753316: Current epoch: 102, loss: 0.7810431122779846, validation loss: 1.7082512378692627
2024-03-20 20:22:15.117576:2024-03-20 20:22:15.117526: Current epoch: 103, loss: 0.7385764122009277, validation loss: 1.6723690032958984
2024-03-20 20:22:15.516330:2024-03-20 20:22:15.516288: Current epoch: 104, loss: 0.7838271856307983, validation loss: 1.712890625
2024-03-20 20:22:15.839975:2024-03-20 20:22:15.839862: Current epoch: 105, loss: 0.8581081032752991, validation loss: 2.143125534057617
2024-03-20 20:22:16.168435:2024-03-20 20:22:16.168377: Current epoch: 106, loss: 0.8997613787651062, validation loss: 1.857225775718689
2024-03-20 20:22:16.537521:2024-03-20 20:22:16.537484: Current epoch: 107, loss: 0.983822226524353, validation loss: 1.7688738107681274
2024-03-20 20:22:16.947206:2024-03-20 20:22:16.947160: Current epoch: 108, loss: 0.958312451839447, validation loss: 1.7701956033706665
2024-03-20 20:22:17.243644:2024-03-20 20:22:17.243575: Current epoch: 109, loss: 0.7864721417427063, validation loss: 1.6813651323318481
2024-03-20 20:22:21.732445:2024-03-20 20:22:21.732407: Current epoch: 110, loss: 0.7453169822692871, validation loss: 1.6837893724441528
2024-03-20 20:22:22.021141:2024-03-20 20:22:22.021101: Current epoch: 111, loss: 0.8137211203575134, validation loss: 1.6670573949813843
2024-03-20 20:22:22.347214:2024-03-20 20:22:22.347154: Current epoch: 112, loss: 0.717984676361084, validation loss: 1.6859097480773926
2024-03-20 20:22:22.662268:2024-03-20 20:22:22.662232: Current epoch: 113, loss: 0.7308185696601868, validation loss: 1.730947732925415
2024-03-20 20:22:23.016364:2024-03-20 20:22:23.016309: Current epoch: 114, loss: 0.8030788898468018, validation loss: 1.8819255828857422
2024-03-20 20:22:23.364065:2024-03-20 20:22:23.364005: Current epoch: 115, loss: 0.9678195118904114, validation loss: 1.745540738105774
2024-03-20 20:22:23.732428:2024-03-20 20:22:23.732361: Current epoch: 116, loss: 0.6867554783821106, validation loss: 1.8085685968399048
2024-03-20 20:22:24.142174:2024-03-20 20:22:24.142112: Current epoch: 117, loss: 0.7416139245033264, validation loss: 1.733599066734314
2024-03-20 20:22:24.420358:2024-03-20 20:22:24.420313: Current epoch: 118, loss: 0.7261141538619995, validation loss: 1.7010060548782349
2024-03-20 20:22:24.782732:2024-03-20 20:22:24.782685: Current epoch: 119, loss: 0.7978132367134094, validation loss: 1.7067192792892456
2024-03-20 20:22:25.163855:2024-03-20 20:22:25.163789: Current epoch: 120, loss: 0.7152776718139648, validation loss: 1.8114817142486572
2024-03-20 20:22:25.528174:2024-03-20 20:22:25.528111: Current epoch: 121, loss: 0.7850825190544128, validation loss: 1.7910780906677246
2024-03-20 20:22:25.880475:2024-03-20 20:22:25.880405: Current epoch: 122, loss: 0.7359734177589417, validation loss: 1.648794174194336
2024-03-20 20:22:26.209838:2024-03-20 20:22:26.209774: Current epoch: 123, loss: 0.7851260900497437, validation loss: 1.7386747598648071
2024-03-20 20:22:26.504071:2024-03-20 20:22:26.504016: Current epoch: 124, loss: 0.7933816909790039, validation loss: 1.6888079643249512
2024-03-20 20:22:26.857258:2024-03-20 20:22:26.857206: Current epoch: 125, loss: 0.6893162131309509, validation loss: 1.843727946281433
2024-03-20 20:22:27.202562:2024-03-20 20:22:27.202529: Current epoch: 126, loss: 0.7097803950309753, validation loss: 1.6685848236083984
2024-03-20 20:22:27.517301:2024-03-20 20:22:27.517254: Current epoch: 127, loss: 0.7071477174758911, validation loss: 1.746228814125061
2024-03-20 20:22:27.897002:2024-03-20 20:22:27.896960: Current epoch: 128, loss: 0.7184674143791199, validation loss: 1.6479151248931885
2024-03-20 20:22:28.225665:2024-03-20 20:22:28.225619: Current epoch: 129, loss: 0.7000910639762878, validation loss: 1.7166693210601807
2024-03-20 20:22:28.580087:2024-03-20 20:22:28.580033: Current epoch: 130, loss: 0.634229302406311, validation loss: 1.6909117698669434
2024-03-20 20:22:28.946753:2024-03-20 20:22:28.946681: Current epoch: 131, loss: 0.7545625567436218, validation loss: 1.764092206954956
2024-03-20 20:22:29.337192:2024-03-20 20:22:29.337136: Current epoch: 132, loss: 0.7995216250419617, validation loss: 1.80479097366333
2024-03-20 20:22:29.657177:2024-03-20 20:22:29.657140: Current epoch: 133, loss: 0.8697453737258911, validation loss: 1.720173954963684
2024-03-20 20:22:29.967628:2024-03-20 20:22:29.967593: Current epoch: 134, loss: 0.701398491859436, validation loss: 1.8348976373672485
2024-03-20 20:22:30.322017:2024-03-20 20:22:30.321948: Current epoch: 135, loss: 0.6307849287986755, validation loss: 1.722561001777649
2024-03-20 20:22:30.693522:2024-03-20 20:22:30.693449: Current epoch: 136, loss: 0.6183234453201294, validation loss: 1.7395026683807373
2024-03-20 20:22:31.110226:2024-03-20 20:22:31.110165: Current epoch: 137, loss: 0.7583038806915283, validation loss: 1.7538329362869263
2024-03-20 20:22:31.516105:2024-03-20 20:22:31.516040: Current epoch: 138, loss: 0.6424195766448975, validation loss: 1.7858905792236328
2024-03-20 20:22:31.877467:2024-03-20 20:22:31.877417: Current epoch: 139, loss: 0.6242129802703857, validation loss: 1.7498695850372314
2024-03-20 20:22:32.272881:2024-03-20 20:22:32.272824: Current epoch: 140, loss: 0.6498474478721619, validation loss: 1.916085124015808
2024-03-20 20:22:32.677318:2024-03-20 20:22:32.677266: Current epoch: 141, loss: 0.7862945795059204, validation loss: 1.801275610923767
2024-03-20 20:22:33.050333:2024-03-20 20:22:33.050302: Current epoch: 142, loss: 0.7403286695480347, validation loss: 1.7382498979568481
2024-03-20 20:22:33.389966:2024-03-20 20:22:33.389920: Current epoch: 143, loss: 0.6473761200904846, validation loss: 1.6791492700576782
2024-03-20 20:22:33.612894:2024-03-20 20:22:33.612864: Current epoch: 144, loss: 0.6855834722518921, validation loss: 1.714796781539917
2024-03-20 20:22:33.960681:2024-03-20 20:22:33.960623: Current epoch: 145, loss: 0.6743985414505005, validation loss: 1.7572896480560303
2024-03-20 20:22:34.321999:2024-03-20 20:22:34.321961: Current epoch: 146, loss: 0.6532576680183411, validation loss: 1.7397892475128174
2024-03-20 20:22:34.610875:2024-03-20 20:22:34.610804: Current epoch: 147, loss: 0.583095371723175, validation loss: 1.7933684587478638
2024-03-20 20:22:35.038407:2024-03-20 20:22:35.038312: Current epoch: 148, loss: 0.6232470870018005, validation loss: 1.8645777702331543
2024-03-20 20:22:35.359317:2024-03-20 20:22:35.359255: Current epoch: 149, loss: 0.6451547145843506, validation loss: 1.7493257522583008
2024-03-20 20:22:35.615292:2024-03-20 20:22:35.615236: Current epoch: 150, loss: 0.5683795809745789, validation loss: 1.772270679473877
2024-03-20 20:22:35.998362:2024-03-20 20:22:35.998319: Current epoch: 151, loss: 0.634608805179596, validation loss: 1.832779049873352
2024-03-20 20:22:36.336298:2024-03-20 20:22:36.336255: Current epoch: 152, loss: 0.6967703104019165, validation loss: 1.8011847734451294
2024-03-20 20:22:36.774523:2024-03-20 20:22:36.774473: Current epoch: 153, loss: 0.768139123916626, validation loss: 1.6704304218292236
2024-03-20 20:22:37.159510:2024-03-20 20:22:37.159424: Current epoch: 154, loss: 0.613274097442627, validation loss: 1.756488561630249
2024-03-20 20:22:37.400090:2024-03-20 20:22:37.400058: Current epoch: 155, loss: 0.7134131193161011, validation loss: 1.7578656673431396
2024-03-20 20:22:37.762548:2024-03-20 20:22:37.762496: Current epoch: 156, loss: 0.6548472046852112, validation loss: 1.7636946439743042
2024-03-20 20:22:38.139253:2024-03-20 20:22:38.139201: Current epoch: 157, loss: 0.6965897679328918, validation loss: 1.8430473804473877
2024-03-20 20:22:38.531181:2024-03-20 20:22:38.531140: Current epoch: 158, loss: 0.7444455027580261, validation loss: 1.8300023078918457
2024-03-20 20:22:38.774220:2024-03-20 20:22:38.774182: Current epoch: 159, loss: 0.785288393497467, validation loss: 1.7703989744186401
2024-03-20 20:22:39.155405:2024-03-20 20:22:39.155349: Current epoch: 160, loss: 0.6405645608901978, validation loss: 1.7366927862167358
2024-03-20 20:22:39.554765:2024-03-20 20:22:39.554703: Current epoch: 161, loss: 0.707760751247406, validation loss: 1.7230970859527588
2024-03-20 20:22:40.013311:2024-03-20 20:22:40.013264: Current epoch: 162, loss: 0.7116732001304626, validation loss: 1.8655873537063599
2024-03-20 20:22:40.204980:2024-03-20 20:22:40.204934: Current epoch: 163, loss: 0.7699312567710876, validation loss: 1.7782435417175293
2024-03-20 20:22:40.379779:2024-03-20 20:22:40.379700: Current epoch: 164, loss: 0.73508220911026, validation loss: 1.730526089668274
2024-03-20 20:22:40.628987:2024-03-20 20:22:40.628875: Current epoch: 165, loss: 0.6444500684738159, validation loss: 1.8035387992858887
2024-03-20 20:22:41.029133:2024-03-20 20:22:41.029073: Current epoch: 166, loss: 0.6501306891441345, validation loss: 1.7199546098709106
2024-03-20 20:22:41.421419:2024-03-20 20:22:41.421381: Current epoch: 167, loss: 0.620026707649231, validation loss: 1.8218967914581299
2024-03-20 20:22:41.883830:2024-03-20 20:22:41.883775: Current epoch: 168, loss: 0.6527805924415588, validation loss: 1.6358115673065186
2024-03-20 20:22:42.222119:2024-03-20 20:22:42.222051: Current epoch: 169, loss: 0.5341611504554749, validation loss: 1.8222440481185913
2024-03-20 20:22:42.641583:2024-03-20 20:22:42.641454: Current epoch: 170, loss: 0.6555984616279602, validation loss: 1.7870781421661377
2024-03-20 20:22:42.790502:the test error is  [2.097926378250122, 2.097926378250122]
2024-03-20 20:22:47.430237:saved model to sample/alignn_bert-base-uncased_chemnlp_prop_Tc_supercon
2024-03-20 20:22:47.697878:done